{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk==3.8.1\n",
        "import nltk as n\n",
        "import numpy as np\n",
        "import random\n",
        "import string\n",
        "import io\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from nltk import pos_tag\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "n.download('wordnet')\n",
        "n.download('punkt')\n",
        "with open('chatbot dataset.txt','r',encoding='utf8',errors='ignore') as ch:\n",
        "  a=ch.read()\n",
        "n.download('averaged_perceptron_tagger')\n",
        "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
        "sentence=n.sent_tokenize(a)\n",
        "word=n.word_tokenize(a)\n",
        "l=WordNetLemmatizer()\n",
        "def lemma(t):\n",
        "  return [l.lemmatize(word) for word in t]\n",
        "def lemmnorm(t):\n",
        "  return lemma(n.word_tokenize(t.lower().translate(remove_punct_dict)))\n",
        "general_io=('hi','hello','hey')\n",
        "general_op=['hello','hi,i am glad talking to you','hi there,how can i assist you']\n",
        "def general(t):\n",
        "  for i in general_io:\n",
        "    if i in t:\n",
        "      return random.choice(general_op)\n",
        "def op(t):\n",
        "  resp=\"\"\n",
        "  sentence.append(t)\n",
        "  vectorizer = TfidfVectorizer(tokenizer=lemmnorm)\n",
        "  tfidf = vectorizer.fit_transform(sentence)\n",
        "  vals = cosine_similarity(tfidf[-1], tfidf)\n",
        "  idx=vals.argsort()[0][-2]\n",
        "  flat = vals.flatten()\n",
        "  flat.sort()\n",
        "  req_tfidf = flat[-2]\n",
        "  if(req_tfidf==0):\n",
        "    resp=resp+\"sorry,i dont understand\"\n",
        "    return resp\n",
        "  else:\n",
        "    resp = resp+sentence[idx]\n",
        "    return resp\n",
        "print(\"AKSHITHA:I AM HERE TO ASSIST YOU\")\n",
        "a=True\n",
        "while (a==True):\n",
        "  t=input().lower()\n",
        "  if(general(t)!=None):\n",
        "        print(\"AKSHITHA:\",end='')\n",
        "        print(general(t))\n",
        "  if(t=='bye'):\n",
        "      print(\"AKSHITHA:BYE\")\n",
        "      a=False\n",
        "      break\n",
        "\n",
        "  else:\n",
        "      print(\"AKSHITHA:\",end='')\n",
        "      print(op(t))\n",
        "      sentence.remove(t)\n",
        "\n",
        "  a=True\n"
      ],
      "metadata": {
        "id": "v8iQLNG-19vJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e95d8e01-cca2-452d-a86d-b47f38d4aaf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk==3.8.1 in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk==3.8.1) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk==3.8.1) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk==3.8.1) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk==3.8.1) (4.66.4)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AKSHITHA:I AM HERE TO ASSIST YOU\n",
            "hi\n",
            "AKSHITHA:hello\n",
            "AKSHITHA:Hello\tHi\n",
            "Hi\tHello\n",
            "Greetings!\n",
            "what is your age\n",
            "AKSHITHA:What is your age\tI am still young by your standards.\n",
            "who wrote vineland\n",
            "AKSHITHA:who wrote vineland\tThomas Pynchon.\n",
            "who is your boss\n",
            "AKSHITHA:Who is your boss\tI like to think of myself as self-employed.\n",
            "bye\n",
            "AKSHITHA:BYE\n"
          ]
        }
      ]
    }
  ]
}